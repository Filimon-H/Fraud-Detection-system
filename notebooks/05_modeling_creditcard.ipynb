{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2.2: Model Building - Credit Card Fraud Detection\n",
    "\n",
    "## Objective\n",
    "Build and evaluate classification models for bank credit card fraud detection:\n",
    "1. Train a **baseline** model (Logistic Regression)\n",
    "2. Train an **ensemble** model (Random Forest)\n",
    "3. Compare models and select the best\n",
    "\n",
    "## Dataset Characteristics\n",
    "- Features are **anonymized PCA components** (V1-V28) plus `Time` and `Amount`\n",
    "- All features are **numeric** (simpler preprocessing)\n",
    "- Highly imbalanced (typical for credit card fraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Project imports\n",
    "from src.data.loader import load_creditcard_data\n",
    "from src.modeling.pipelines import build_creditcard_pipeline, get_model_name\n",
    "from src.modeling.train import train_and_evaluate, cross_validate_model, save_model, compare_models\n",
    "from src.modeling.metrics import (\n",
    "    plot_confusion_matrix,\n",
    "    plot_precision_recall_curve,\n",
    "    get_classification_report_df,\n",
    ")\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Credit Card Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the credit card dataset\n",
    "DATA_PATH = project_root / \"data\" / \"raw\" / \"creditcard.csv\"\n",
    "\n",
    "df = load_creditcard_data(DATA_PATH)\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class distribution\n",
    "print(\"Class Distribution:\")\n",
    "class_counts = df['Class'].value_counts()\n",
    "print(class_counts)\n",
    "print(f\"\\nFraud rate: {df['Class'].mean() * 100:.4f}%\")\n",
    "print(f\"Imbalance ratio: 1:{class_counts[0] / class_counts[1]:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "# V1-V28 are PCA components, Time and Amount are the only interpretable features\n",
    "FEATURE_COLS = [col for col in df.columns if col != 'Class']\n",
    "TARGET = 'Class'\n",
    "\n",
    "print(f\"Features: {len(FEATURE_COLS)} columns\")\n",
    "print(f\"Feature names: {FEATURE_COLS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare X and y\n",
    "X = df[FEATURE_COLS].copy()\n",
    "y = df[TARGET].copy()\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "fraud_rate = df['Class'].mean() * 100\n",
    "imbalance_ratio = class_counts[0] / class_counts[1]\n",
    "\n",
    "display(\n",
    "    Markdown(\n",
    "        f\"\"\"\n",
    "### Interpretation: Credit Card Dataset Overview\n",
    "\n",
    "- **Dataset size**: `{df.shape[0]:,}` transactions Ã— `{df.shape[1]}` columns\n",
    "- **Fraud rate**: `{fraud_rate:.4f}%` (highly imbalanced)\n",
    "- **Imbalance ratio**: approximately **1:{imbalance_ratio:.0f}**\n",
    "- **Features**: `V1`-`V28` (PCA components, anonymized), `Time`, `Amount`\n",
    "\n",
    "**Note on interpretability**\n",
    "- The V1-V28 features are the result of PCA transformation for privacy.\n",
    "- Only `Time` and `Amount` have direct business meaning.\n",
    "- SHAP analysis will still show which components drive predictions, but interpretation is abstract.\n",
    "\"\"\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train-Test Split (Stratified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]:,} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]:,} samples\")\n",
    "print(f\"\\nTraining class distribution:\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"\\nTest class distribution:\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Baseline Model: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build logistic regression pipeline with SMOTE\n",
    "lr_pipeline = build_creditcard_pipeline(\n",
    "    model_type=\"logistic\",\n",
    "    use_smote=True,\n",
    "    random_state=RANDOM_STATE,\n",
    ")\n",
    "\n",
    "print(\"Logistic Regression Pipeline:\")\n",
    "print(lr_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate\n",
    "print(\"Training Logistic Regression...\")\n",
    "lr_model, lr_metrics, lr_threshold = train_and_evaluate(\n",
    "    lr_pipeline,\n",
    "    X_train, y_train,\n",
    "    X_test, y_test,\n",
    "    threshold=0.5,\n",
    ")\n",
    "\n",
    "print(\"\\nLogistic Regression Results:\")\n",
    "for key, value in lr_metrics.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {key}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "plot_confusion_matrix(y_test.values, y_pred_lr, title=\"Logistic Regression - Confusion Matrix\", ax=ax)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print(\"Classification Report - Logistic Regression:\")\n",
    "display(get_classification_report_df(y_test.values, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Ensemble Model: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Random Forest pipeline with SMOTE\n",
    "rf_pipeline = build_creditcard_pipeline(\n",
    "    model_type=\"random_forest\",\n",
    "    use_smote=True,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    ")\n",
    "\n",
    "print(\"Random Forest Pipeline:\")\n",
    "print(rf_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate\n",
    "print(\"Training Random Forest...\")\n",
    "rf_model, rf_metrics, rf_threshold = train_and_evaluate(\n",
    "    rf_pipeline,\n",
    "    X_train, y_train,\n",
    "    X_test, y_test,\n",
    "    threshold=0.5,\n",
    ")\n",
    "\n",
    "print(\"\\nRandom Forest Results:\")\n",
    "for key, value in rf_metrics.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {key}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "plot_confusion_matrix(y_test.values, y_pred_rf, title=\"Random Forest - Confusion Matrix\", ax=ax)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print(\"Classification Report - Random Forest:\")\n",
    "display(get_classification_report_df(y_test.values, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all models\n",
    "results = {\n",
    "    \"Logistic Regression + SMOTE\": lr_metrics,\n",
    "    \"Random Forest + SMOTE\": rf_metrics,\n",
    "}\n",
    "\n",
    "comparison_df = compare_models(results)\n",
    "print(\"Model Comparison (sorted by AUC-PR):\")\n",
    "display(comparison_df.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision-Recall curves comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "y_proba_lr = lr_model.predict_proba(X_test)[:, 1]\n",
    "y_proba_rf = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "plot_precision_recall_curve(y_test.values, y_proba_lr, model_name=\"Logistic Regression\", ax=ax)\n",
    "plot_precision_recall_curve(y_test.values, y_proba_rf, model_name=\"Random Forest\", ax=ax)\n",
    "\n",
    "ax.legend(loc=\"best\")\n",
    "ax.set_title(\"Precision-Recall Curves - Credit Card Models\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Side-by-side confusion matrices\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "plot_confusion_matrix(y_test.values, y_pred_lr, title=\"Logistic Regression\", ax=axes[0])\n",
    "plot_confusion_matrix(y_test.values, y_pred_rf, title=\"Random Forest\", ax=axes[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "best_model_name = comparison_df.index[0]\n",
    "best_auc_pr = comparison_df.iloc[0]['auc_pr']\n",
    "\n",
    "lr_auc = lr_metrics.get('auc_pr', 0)\n",
    "rf_auc = rf_metrics.get('auc_pr', 0)\n",
    "\n",
    "display(\n",
    "    Markdown(\n",
    "        f\"\"\"\n",
    "### Interpretation: Model Comparison (Credit Card)\n",
    "\n",
    "| Model | AUC-PR | F1 | Precision | Recall |\n",
    "|-------|--------|----|-----------|---------|\n",
    "| Logistic Regression | {lr_metrics.get('auc_pr', 0):.4f} | {lr_metrics.get('f1', 0):.4f} | {lr_metrics.get('precision', 0):.4f} | {lr_metrics.get('recall', 0):.4f} |\n",
    "| Random Forest | {rf_metrics.get('auc_pr', 0):.4f} | {rf_metrics.get('f1', 0):.4f} | {rf_metrics.get('precision', 0):.4f} | {rf_metrics.get('recall', 0):.4f} |\n",
    "\n",
    "**Best Model**: `{best_model_name}` with AUC-PR = `{best_auc_pr:.4f}`\n",
    "\n",
    "**Observations**\n",
    "- Credit card fraud detection with PCA features often shows strong baseline performance.\n",
    "- The ensemble model captures additional patterns in the anonymized feature space.\n",
    "- Both models benefit from SMOTE to handle the extreme class imbalance.\n",
    "\"\"\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Importance (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature importance\n",
    "rf_classifier = rf_model.named_steps['classifier']\n",
    "importances = rf_classifier.feature_importances_\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': FEATURE_COLS,\n",
    "    'importance': importances\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 15 Features by Importance:\")\n",
    "display(importance_df.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot top 15 features\n",
    "top_n = 15\n",
    "top_features = importance_df.head(top_n)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.barh(top_features['feature'], top_features['importance'], color='#e74c3c')\n",
    "ax.set_xlabel('Importance')\n",
    "ax.set_ylabel('Feature')\n",
    "ax.set_title(f'Top {top_n} Feature Importances (Random Forest - Credit Card)')\n",
    "ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "top5 = importance_df.head(5)['feature'].tolist()\n",
    "\n",
    "display(\n",
    "    Markdown(\n",
    "        f\"\"\"\n",
    "### Interpretation: Feature Importance (Credit Card)\n",
    "\n",
    "**Top 5 most important features**:\n",
    "1. `{top5[0]}`\n",
    "2. `{top5[1]}`\n",
    "3. `{top5[2]}`\n",
    "4. `{top5[3]}`\n",
    "5. `{top5[4]}`\n",
    "\n",
    "**Note on interpretation**\n",
    "- Since V1-V28 are PCA-transformed, we cannot directly interpret what they represent.\n",
    "- If `Amount` or `Time` rank highly, those are actionable features.\n",
    "- SHAP analysis in Task 3 will provide more granular insights into prediction drivers.\n",
    "\"\"\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models\n",
    "models_dir = project_root / \"models\"\n",
    "\n",
    "# Save Random Forest\n",
    "rf_path = save_model(rf_model, \"creditcard_random_forest\", rf_metrics, models_dir)\n",
    "print(f\"Random Forest saved to: {rf_path}\")\n",
    "\n",
    "# Save Logistic Regression\n",
    "lr_path = save_model(lr_model, \"creditcard_logistic_regression\", lr_metrics, models_dir)\n",
    "print(f\"Logistic Regression saved to: {lr_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary: Task 2 (Credit Card) Complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "best_model_name = comparison_df.index[0]\n",
    "best_metrics = results[best_model_name]\n",
    "\n",
    "display(\n",
    "    Markdown(\n",
    "        f\"\"\"\n",
    "## Summary: Task 2 - Credit Card Fraud Model\n",
    "\n",
    "### Models Trained\n",
    "1. **Logistic Regression + SMOTE** (baseline)\n",
    "2. **Random Forest + SMOTE** (ensemble)\n",
    "\n",
    "### Best Model: `{best_model_name}`\n",
    "- **AUC-PR**: `{best_metrics.get('auc_pr', 0):.4f}`\n",
    "- **F1-Score**: `{best_metrics.get('f1', 0):.4f}`\n",
    "- **Precision**: `{best_metrics.get('precision', 0):.4f}`\n",
    "- **Recall**: `{best_metrics.get('recall', 0):.4f}`\n",
    "\n",
    "### Dataset Characteristics\n",
    "- `{df.shape[0]:,}` transactions with `{fraud_rate:.4f}%` fraud rate\n",
    "- Features are PCA-transformed (V1-V28) plus Time and Amount\n",
    "- Extreme imbalance handled with SMOTE\n",
    "\n",
    "### Files Saved\n",
    "- `models/creditcard_random_forest.joblib`\n",
    "- `models/creditcard_logistic_regression.joblib`\n",
    "\n",
    "### Next Steps\n",
    "- Proceed to Task 3 for SHAP explainability analysis\n",
    "- Focus SHAP analysis on the e-commerce model (more interpretable features)\n",
    "\"\"\"\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
