{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3.1: Model Explainability - E-commerce Fraud Detection\n",
    "\n",
    "## Objective\n",
    "Explain model predictions using SHAP (SHapley Additive exPlanations):\n",
    "1. **Global explainability**: Which features matter most overall?\n",
    "2. **Local explainability**: Why did the model flag specific transactions?\n",
    "\n",
    "## Why Explainability Matters\n",
    "- **Regulatory compliance**: Many jurisdictions require explanations for automated decisions\n",
    "- **Trust**: Business stakeholders need to understand model behavior\n",
    "- **Debugging**: Identify if model relies on spurious correlations\n",
    "- **Actionable insights**: Translate model patterns into business rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import shap\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Project imports\n",
    "from src.explainability.shap_utils import (\n",
    "    get_feature_names_from_pipeline,\n",
    "    transform_for_explanation,\n",
    "    create_tree_explainer,\n",
    "    compute_shap_values,\n",
    "    plot_shap_summary,\n",
    "    plot_shap_bar,\n",
    "    plot_shap_dependence,\n",
    "    plot_shap_waterfall,\n",
    "    get_example_cases,\n",
    ")\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "# Initialize SHAP JS visualization\n",
    "shap.initjs()\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Model and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model (Random Forest)\n",
    "MODEL_PATH = project_root / \"models\" / \"fraud_random_forest.joblib\"\n",
    "\n",
    "model = joblib.load(MODEL_PATH)\n",
    "print(f\"Loaded model from: {MODEL_PATH}\")\n",
    "print(f\"Pipeline steps: {list(model.named_steps.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load feature-engineered data\n",
    "DATA_PATH = project_root / \"data\" / \"processed\" / \"fraud_featured.parquet\"\n",
    "\n",
    "df = pd.read_parquet(DATA_PATH)\n",
    "print(f\"Loaded data: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (same as Task 2)\n",
    "NUMERIC_FEATURES = [\n",
    "    'purchase_value', 'age', 'hour_of_day', 'day_of_week', 'is_weekend',\n",
    "    'time_since_signup', 'tx_count_user_id_1h', 'tx_count_user_id_24h',\n",
    "    'user_total_transactions'\n",
    "]\n",
    "\n",
    "CATEGORICAL_FEATURES = ['source', 'browser', 'sex', 'country']\n",
    "\n",
    "TARGET = 'class'\n",
    "\n",
    "X = df[NUMERIC_FEATURES + CATEGORICAL_FEATURES].copy()\n",
    "y = df[TARGET].copy()\n",
    "\n",
    "print(f\"Features: {X.shape[1]}\")\n",
    "print(f\"Target distribution: {y.value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the same train/test split as Task 2\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Test set size: {X_test.shape[0]:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare for SHAP Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature names after preprocessing (including one-hot encoded)\n",
    "feature_names = get_feature_names_from_pipeline(\n",
    "    model,\n",
    "    NUMERIC_FEATURES,\n",
    "    CATEGORICAL_FEATURES\n",
    ")\n",
    "\n",
    "print(f\"Total features after encoding: {len(feature_names)}\")\n",
    "print(f\"\\nFirst 20 feature names:\")\n",
    "print(feature_names[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform test data for SHAP (using only preprocessor, not SMOTE)\n",
    "X_test_transformed = transform_for_explanation(model, X_test)\n",
    "\n",
    "print(f\"Transformed test data shape: {X_test_transformed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SHAP explainer for the Random Forest classifier\n",
    "explainer = create_tree_explainer(model)\n",
    "\n",
    "print(f\"Explainer type: {type(explainer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute SHAP values (sample for speed)\n",
    "# For large datasets, we sample to speed up computation\n",
    "SAMPLE_SIZE = 5000  # Adjust based on dataset size and available time\n",
    "\n",
    "print(f\"Computing SHAP values for {min(SAMPLE_SIZE, len(X_test_transformed)):,} samples...\")\n",
    "print(\"(This may take a few minutes)\")\n",
    "\n",
    "shap_values = compute_shap_values(\n",
    "    explainer,\n",
    "    X_test_transformed,\n",
    "    sample_size=SAMPLE_SIZE,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\"SHAP values computed: {shap_values.values.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Global Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 SHAP Summary Plot (Beeswarm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary plot showing feature impact distribution\n",
    "plot_shap_summary(\n",
    "    shap_values,\n",
    "    feature_names,\n",
    "    max_display=20,\n",
    "    plot_type=\"dot\",\n",
    "    title=\"SHAP Summary Plot - E-commerce Fraud Model\",\n",
    "    save_path=project_root / \"reports\" / \"figures\" / \"shap_summary_fraud.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Get top features for interpretation\n",
    "mean_abs_shap = np.abs(shap_values.values).mean(axis=0)\n",
    "top_indices = np.argsort(mean_abs_shap)[-5:][::-1]\n",
    "top_features = [feature_names[i] for i in top_indices]\n",
    "\n",
    "display(\n",
    "    Markdown(\n",
    "        f\"\"\"\n",
    "### Interpretation: SHAP Summary Plot\n",
    "\n",
    "The beeswarm plot shows how each feature impacts model predictions:\n",
    "- **X-axis**: SHAP value (positive = pushes toward fraud, negative = pushes toward non-fraud)\n",
    "- **Color**: Feature value (red = high, blue = low)\n",
    "- **Each dot**: One transaction\n",
    "\n",
    "**Top 5 most impactful features**:\n",
    "1. `{top_features[0]}`\n",
    "2. `{top_features[1]}`\n",
    "3. `{top_features[2]}`\n",
    "4. `{top_features[3]}`\n",
    "5. `{top_features[4]}`\n",
    "\n",
    "**Key patterns to look for**:\n",
    "- If `time_since_signup` shows red (high values) pushing left (non-fraud), it means established accounts are less risky.\n",
    "- If velocity features (`tx_count_*`) show red pushing right, high transaction frequency indicates fraud.\n",
    "\"\"\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 SHAP Feature Importance (Bar Plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot of mean absolute SHAP values\n",
    "importance_df = plot_shap_bar(\n",
    "    shap_values,\n",
    "    feature_names,\n",
    "    max_display=20,\n",
    "    title=\"SHAP Feature Importance - E-commerce Fraud Model\",\n",
    "    save_path=project_root / \"reports\" / \"figures\" / \"shap_importance_fraud.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show top features table\n",
    "print(\"Top 15 Features by SHAP Importance:\")\n",
    "display(importance_df.head(15).round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 SHAP Dependence Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependence plot for top numeric feature\n",
    "# Find the top numeric feature from our original list\n",
    "top_numeric = None\n",
    "for feat in importance_df['feature'].values:\n",
    "    if feat in NUMERIC_FEATURES:\n",
    "        top_numeric = feat\n",
    "        break\n",
    "\n",
    "if top_numeric:\n",
    "    print(f\"Dependence plot for top numeric feature: {top_numeric}\")\n",
    "    plot_shap_dependence(\n",
    "        shap_values,\n",
    "        top_numeric,\n",
    "        feature_names,\n",
    "        title=f\"SHAP Dependence: {top_numeric}\",\n",
    "        save_path=project_root / \"reports\" / \"figures\" / f\"shap_dependence_{top_numeric}.png\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependence plot for time_since_signup (often very important for fraud)\n",
    "if 'time_since_signup' in feature_names:\n",
    "    plot_shap_dependence(\n",
    "        shap_values,\n",
    "        'time_since_signup',\n",
    "        feature_names,\n",
    "        title=\"SHAP Dependence: time_since_signup\",\n",
    "        save_path=project_root / \"reports\" / \"figures\" / \"shap_dependence_time_since_signup.png\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependence plot for transaction velocity\n",
    "if 'tx_count_user_id_1h' in feature_names:\n",
    "    plot_shap_dependence(\n",
    "        shap_values,\n",
    "        'tx_count_user_id_1h',\n",
    "        feature_names,\n",
    "        title=\"SHAP Dependence: tx_count_user_id_1h\",\n",
    "        save_path=project_root / \"reports\" / \"figures\" / \"shap_dependence_velocity_1h.png\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(\n",
    "    Markdown(\n",
    "        \"\"\"\n",
    "### Interpretation: Dependence Plots\n",
    "\n",
    "Dependence plots show how a feature's value relates to its SHAP impact:\n",
    "\n",
    "**Common patterns in fraud detection:**\n",
    "- **`time_since_signup`**: Very short times (seconds/minutes) often show high positive SHAP (fraud signal). Established accounts show negative SHAP (safe signal).\n",
    "- **`tx_count_user_id_1h`**: Multiple transactions in 1 hour typically push predictions toward fraud.\n",
    "- **`purchase_value`**: May show non-linear patterns (both very low and very high amounts can be suspicious).\n",
    "\n",
    "**Business translation:**\n",
    "- New accounts making rapid transactions are flagged as high risk.\n",
    "- This validates our feature engineering choices in Task 1.\n",
    "\"\"\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Local Explainability (Individual Predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions on test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(f\"Predictions made: {len(y_pred):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get example cases for each outcome type\n",
    "example_cases = get_example_cases(\n",
    "    y_test.values,\n",
    "    y_pred,\n",
    "    y_proba,\n",
    "    n_examples=3\n",
    ")\n",
    "\n",
    "print(\"Example cases found:\")\n",
    "for case_type, indices in example_cases.items():\n",
    "    print(f\"  {case_type}: {len(indices)} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute SHAP values for all test samples (needed for waterfall plots)\n",
    "# We'll use the full test set for local explanations\n",
    "print(\"Computing SHAP values for local explanations...\")\n",
    "shap_values_full = explainer(X_test_transformed)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 True Positive: Correctly Caught Fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain a True Positive case\n",
    "if example_cases['true_positive']:\n",
    "    tp_idx = example_cases['true_positive'][0]\n",
    "    \n",
    "    print(f\"True Positive Example (index {tp_idx}):\")\n",
    "    print(f\"  Actual: Fraud | Predicted: Fraud | Probability: {y_proba[tp_idx]:.4f}\")\n",
    "    print(f\"\\nKey feature values:\")\n",
    "    for feat in NUMERIC_FEATURES[:5]:\n",
    "        print(f\"  {feat}: {X_test.iloc[tp_idx][feat]}\")\n",
    "    \n",
    "    plot_shap_waterfall(\n",
    "        shap_values_full,\n",
    "        tp_idx,\n",
    "        feature_names,\n",
    "        max_display=15,\n",
    "        title=f\"True Positive: Why this fraud was caught (prob={y_proba[tp_idx]:.3f})\",\n",
    "    )\n",
    "else:\n",
    "    print(\"No True Positive examples found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 False Positive: Incorrectly Flagged Legitimate Transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain a False Positive case\n",
    "if example_cases['false_positive']:\n",
    "    fp_idx = example_cases['false_positive'][0]\n",
    "    \n",
    "    print(f\"False Positive Example (index {fp_idx}):\")\n",
    "    print(f\"  Actual: Legitimate | Predicted: Fraud | Probability: {y_proba[fp_idx]:.4f}\")\n",
    "    print(f\"\\nKey feature values:\")\n",
    "    for feat in NUMERIC_FEATURES[:5]:\n",
    "        print(f\"  {feat}: {X_test.iloc[fp_idx][feat]}\")\n",
    "    \n",
    "    plot_shap_waterfall(\n",
    "        shap_values_full,\n",
    "        fp_idx,\n",
    "        feature_names,\n",
    "        max_display=15,\n",
    "        title=f\"False Positive: Why this legitimate tx was flagged (prob={y_proba[fp_idx]:.3f})\",\n",
    "    )\n",
    "else:\n",
    "    print(\"No False Positive examples found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 False Negative: Missed Fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain a False Negative case\n",
    "if example_cases['false_negative']:\n",
    "    fn_idx = example_cases['false_negative'][0]\n",
    "    \n",
    "    print(f\"False Negative Example (index {fn_idx}):\")\n",
    "    print(f\"  Actual: Fraud | Predicted: Legitimate | Probability: {y_proba[fn_idx]:.4f}\")\n",
    "    print(f\"\\nKey feature values:\")\n",
    "    for feat in NUMERIC_FEATURES[:5]:\n",
    "        print(f\"  {feat}: {X_test.iloc[fn_idx][feat]}\")\n",
    "    \n",
    "    plot_shap_waterfall(\n",
    "        shap_values_full,\n",
    "        fn_idx,\n",
    "        feature_names,\n",
    "        max_display=15,\n",
    "        title=f\"False Negative: Why this fraud was missed (prob={y_proba[fn_idx]:.3f})\",\n",
    "    )\n",
    "else:\n",
    "    print(\"No False Negative examples found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(\n",
    "    Markdown(\n",
    "        \"\"\"\n",
    "### Interpretation: Local Explanations\n",
    "\n",
    "**Waterfall plots** show how each feature pushed the prediction from the baseline (average) toward the final output:\n",
    "\n",
    "- **Red bars**: Features pushing toward fraud prediction\n",
    "- **Blue bars**: Features pushing toward legitimate prediction\n",
    "- **E[f(X)]**: Expected value (baseline)\n",
    "- **f(x)**: Final prediction value\n",
    "\n",
    "**What we learn from each case type:**\n",
    "\n",
    "1. **True Positives**: Validate that the model catches fraud for the right reasons (e.g., new account + high velocity)\n",
    "\n",
    "2. **False Positives**: Understand why legitimate transactions look suspicious. This helps:\n",
    "   - Refine features\n",
    "   - Adjust threshold\n",
    "   - Design better customer experience for flagged transactions\n",
    "\n",
    "3. **False Negatives**: Critical for understanding model blindspots. Fraudsters that \"look normal\" reveal feature gaps.\n",
    "\"\"\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary: Task 3 (E-commerce) Complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "top5_str = \"\\n\".join([f\"{i+1}. `{f}` (mean |SHAP| = {importance_df.iloc[i]['mean_abs_shap']:.4f})\" \n",
    "                       for i, f in enumerate(importance_df.head(5)['feature'])])\n",
    "\n",
    "display(\n",
    "    Markdown(\n",
    "        f\"\"\"\n",
    "## Summary: Task 3 - E-commerce Fraud Model Explainability\n",
    "\n",
    "### Global Insights\n",
    "\n",
    "**Top 5 most important features by SHAP:**\n",
    "{top5_str}\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "1. **Time-based features** (e.g., `time_since_signup`) are strong fraud indicators.\n",
    "   - New accounts are riskier.\n",
    "   - This aligns with known fraud patterns (create-and-use attacks).\n",
    "\n",
    "2. **Velocity features** (e.g., `tx_count_user_id_1h`) capture behavioral fraud signals.\n",
    "   - High transaction frequency in short windows indicates automated fraud.\n",
    "\n",
    "3. **Geographic features** (country-related) may show regional fraud patterns.\n",
    "   - Useful for risk-based authentication.\n",
    "\n",
    "### Business Recommendations\n",
    "\n",
    "Based on SHAP analysis:\n",
    "- **Step-up authentication** for new accounts (< threshold time since signup)\n",
    "- **Velocity limits** or additional verification for rapid transactions\n",
    "- **Geographic risk scoring** integrated with payment flow\n",
    "\n",
    "### Files Saved\n",
    "- `reports/figures/shap_summary_fraud.png`\n",
    "- `reports/figures/shap_importance_fraud.png`\n",
    "- `reports/figures/shap_dependence_*.png`\n",
    "\n",
    "### Next Steps\n",
    "- Run `07_shap_explainability_creditcard.ipynb` for credit card model\n",
    "- Use insights to refine feature engineering or business rules\n",
    "- Consider deploying model with real-time SHAP explanations for flagged transactions\n",
    "\"\"\"\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
