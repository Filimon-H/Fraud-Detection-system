{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1.1: Exploratory Data Analysis - Fraud Data\n",
    "\n",
    "## Objective\n",
    "Explore and understand the e-commerce fraud dataset (`Fraud_Data.csv`) to:\n",
    "1. Understand data structure, types, and quality\n",
    "2. Identify missing values and duplicates\n",
    "3. Analyze class distribution (fraud vs non-fraud)\n",
    "4. Discover patterns and relationships in features\n",
    "\n",
    "## Key Questions\n",
    "- How imbalanced is the fraud class?\n",
    "- What are the distributions of key features?\n",
    "- Are there obvious patterns that distinguish fraud from legitimate transactions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path for imports\n",
    "project_root = Path.cwd().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Project imports\n",
    "from src.data.loader import load_fraud_data\n",
    "from src.data.cleaning import clean_fraud_data, get_missing_value_summary, get_duplicate_summary\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the raw fraud data\n",
    "DATA_PATH = project_root / \"data\" / \"raw\" / \"Fraud_Data.csv\"\n",
    "\n",
    "df_raw = load_fraud_data(DATA_PATH)\n",
    "print(f\"Dataset shape: {df_raw.shape}\")\n",
    "print(f\"Columns: {list(df_raw.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First look at the data\n",
    "df_raw.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types and info\n",
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics for numeric columns\n",
    "df_raw.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation: Raw Data Overview\n",
    "\n",
    "*TODO: After running, describe:*\n",
    "- Number of rows and columns\n",
    "- Data types observed\n",
    "- Initial observations about the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_summary = get_missing_value_summary(df_raw)\n",
    "if len(missing_summary) > 0:\n",
    "    print(\"Missing Values Found:\")\n",
    "    display(missing_summary)\n",
    "else:\n",
    "    print(\"No missing values found in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "dup_summary = get_duplicate_summary(df_raw)\n",
    "print(\"Duplicate Analysis:\")\n",
    "for key, value in dup_summary.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation: Data Quality\n",
    "\n",
    "*TODO: After running, describe:*\n",
    "- Were there missing values? In which columns?\n",
    "- Were there duplicates? How many?\n",
    "- What cleaning actions are needed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clean the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply cleaning function\n",
    "df_clean, cleaning_report = clean_fraud_data(df_raw)\n",
    "\n",
    "print(\"Cleaning Report:\")\n",
    "for key, value in cleaning_report.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify cleaned data types\n",
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Class Distribution Analysis (Target Variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class distribution\n",
    "class_counts = df_clean['class'].value_counts()\n",
    "class_pct = df_clean['class'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"Class Distribution:\")\n",
    "print(f\"  Non-Fraud (0): {class_counts[0]:,} ({class_pct[0]:.2f}%)\")\n",
    "print(f\"  Fraud (1):     {class_counts[1]:,} ({class_pct[1]:.2f}%)\")\n",
    "print(f\"\\nImbalance Ratio: 1:{class_counts[0]/class_counts[1]:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Bar chart\n",
    "colors = ['#2ecc71', '#e74c3c']\n",
    "axes[0].bar(['Non-Fraud', 'Fraud'], class_counts.values, color=colors)\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Class Distribution (Count)')\n",
    "for i, v in enumerate(class_counts.values):\n",
    "    axes[0].text(i, v + 500, f'{v:,}', ha='center', fontweight='bold')\n",
    "\n",
    "# Pie chart\n",
    "axes[1].pie(class_counts.values, labels=['Non-Fraud', 'Fraud'], autopct='%1.2f%%',\n",
    "            colors=colors, explode=[0, 0.1])\n",
    "axes[1].set_title('Class Distribution (Percentage)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation: Class Imbalance\n",
    "\n",
    "*TODO: After running, describe:*\n",
    "- What is the exact fraud rate?\n",
    "- How severe is the imbalance?\n",
    "- What are the implications for modeling? (e.g., accuracy is misleading, need SMOTE/undersampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Numeric Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purchase value distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(df_clean['purchase_value'], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Purchase Value ($)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Distribution of Purchase Value')\n",
    "\n",
    "# Box plot\n",
    "axes[1].boxplot(df_clean['purchase_value'], vert=True)\n",
    "axes[1].set_ylabel('Purchase Value ($)')\n",
    "axes[1].set_title('Purchase Value Box Plot')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Purchase Value Statistics:\")\n",
    "print(df_clean['purchase_value'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].hist(df_clean['age'], bins=30, edgecolor='black', alpha=0.7, color='#3498db')\n",
    "axes[0].set_xlabel('Age')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Distribution of Age')\n",
    "\n",
    "axes[1].boxplot(df_clean['age'], vert=True)\n",
    "axes[1].set_ylabel('Age')\n",
    "axes[1].set_title('Age Box Plot')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Age Statistics:\")\n",
    "print(df_clean['age'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical columns analysis\n",
    "cat_cols = ['source', 'browser', 'sex']\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for i, col in enumerate(cat_cols):\n",
    "    value_counts = df_clean[col].value_counts()\n",
    "    axes[i].bar(value_counts.index, value_counts.values, color='#9b59b6', edgecolor='black')\n",
    "    axes[i].set_xlabel(col.capitalize())\n",
    "    axes[i].set_ylabel('Count')\n",
    "    axes[i].set_title(f'Distribution of {col.capitalize()}')\n",
    "    axes[i].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value counts for each categorical\n",
    "for col in cat_cols:\n",
    "    print(f\"\\n{col.upper()}:\")\n",
    "    print(df_clean[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation: Feature Distributions\n",
    "\n",
    "*TODO: After running, describe:*\n",
    "- What is the shape of purchase_value distribution? Any outliers?\n",
    "- What is the age distribution?\n",
    "- Which sources/browsers are most common?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Bivariate Analysis (Features vs Target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purchase value by fraud class\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Box plot\n",
    "df_clean.boxplot(column='purchase_value', by='class', ax=axes[0])\n",
    "axes[0].set_xlabel('Class (0=Non-Fraud, 1=Fraud)')\n",
    "axes[0].set_ylabel('Purchase Value ($)')\n",
    "axes[0].set_title('Purchase Value by Class')\n",
    "plt.suptitle('')  # Remove auto-title\n",
    "\n",
    "# Violin plot\n",
    "parts = axes[1].violinplot(\n",
    "    [df_clean[df_clean['class']==0]['purchase_value'].values,\n",
    "     df_clean[df_clean['class']==1]['purchase_value'].values],\n",
    "    positions=[0, 1]\n",
    ")\n",
    "axes[1].set_xticks([0, 1])\n",
    "axes[1].set_xticklabels(['Non-Fraud', 'Fraud'])\n",
    "axes[1].set_ylabel('Purchase Value ($)')\n",
    "axes[1].set_title('Purchase Value Distribution by Class')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age by fraud class\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "df_clean.boxplot(column='age', by='class', ax=ax)\n",
    "ax.set_xlabel('Class (0=Non-Fraud, 1=Fraud)')\n",
    "ax.set_ylabel('Age')\n",
    "ax.set_title('Age by Class')\n",
    "plt.suptitle('')\n",
    "plt.show()\n",
    "\n",
    "# Statistics by class\n",
    "print(\"Age by Class:\")\n",
    "print(df_clean.groupby('class')['age'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fraud rate by categorical features\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for i, col in enumerate(cat_cols):\n",
    "    fraud_rate = df_clean.groupby(col)['class'].mean() * 100\n",
    "    fraud_rate = fraud_rate.sort_values(ascending=False)\n",
    "    \n",
    "    axes[i].bar(fraud_rate.index, fraud_rate.values, color='#e74c3c', edgecolor='black')\n",
    "    axes[i].set_xlabel(col.capitalize())\n",
    "    axes[i].set_ylabel('Fraud Rate (%)')\n",
    "    axes[i].set_title(f'Fraud Rate by {col.capitalize()}')\n",
    "    axes[i].tick_params(axis='x', rotation=45)\n",
    "    axes[i].axhline(y=df_clean['class'].mean()*100, color='black', linestyle='--', label='Overall')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fraud rate statistics by category\n",
    "for col in cat_cols:\n",
    "    print(f\"\\nFraud Rate by {col.upper()}:\")\n",
    "    fraud_stats = df_clean.groupby(col).agg(\n",
    "        total_count=('class', 'count'),\n",
    "        fraud_count=('class', 'sum'),\n",
    "        fraud_rate=('class', 'mean')\n",
    "    ).round(4)\n",
    "    fraud_stats['fraud_rate'] = (fraud_stats['fraud_rate'] * 100).round(2)\n",
    "    print(fraud_stats.sort_values('fraud_rate', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation: Feature vs Target Relationships\n",
    "\n",
    "*TODO: After running, describe:*\n",
    "- Is there a difference in purchase_value between fraud and non-fraud?\n",
    "- Do certain sources/browsers have higher fraud rates?\n",
    "- Are there any surprising patterns?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary and Next Steps\n",
    "\n",
    "*TODO: Fill in after completing the analysis*\n",
    "\n",
    "### Key Findings\n",
    "1. **Class Imbalance**: [Describe the imbalance ratio]\n",
    "2. **Data Quality**: [Describe missing values, duplicates, cleaning actions]\n",
    "3. **Feature Insights**: [Key patterns discovered]\n",
    "\n",
    "### Next Steps\n",
    "- Proceed to geolocation analysis (IP to country mapping)\n",
    "- Engineer time-based features\n",
    "- Create velocity features\n",
    "- Handle class imbalance for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned data for next notebook\n",
    "output_path = project_root / \"data\" / \"processed\" / \"fraud_cleaned.parquet\"\n",
    "df_clean.to_parquet(output_path, index=False)\n",
    "print(f\"Cleaned data saved to: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
